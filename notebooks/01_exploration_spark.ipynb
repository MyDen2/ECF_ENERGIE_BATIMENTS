{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d97b11e",
   "metadata": {},
   "source": [
    "# Etape 1.1 : Exploration initiale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75411d1",
   "metadata": {},
   "source": [
    "## Charger les donnees de consommation avec PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ad60da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 4.1.1\n",
      "Spark UI: http://host.docker.internal:4040\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "import os\n",
    "\n",
    "# Chemins de toutes les donnees\n",
    "DATA_DIR = \"../data_ecf\"\n",
    "\n",
    "CONSUMPTION_PATH = os.path.join(DATA_DIR, \"consommations_raw.csv\")\n",
    "\n",
    "# Création de la session Spark \n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ECF2\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Reduire les logs\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Spark UI: {spark.sparkContext.uiWebUrl}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1956e6d3",
   "metadata": {},
   "source": [
    "## Analyser le schema infere et identifier les problemes de typage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db16adc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes: 7,758,868\n",
      "Nombre de colonnes: 5\n"
     ]
    }
   ],
   "source": [
    "# Charger le CSV avec inference de schema\n",
    "df_consumption = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(CONSUMPTION_PATH)\n",
    "\n",
    "print(f\"Nombre de lignes: {df_consumption.count():,}\")\n",
    "print(f\"Nombre de colonnes: {len(df_consumption.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ada38fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema infere:\n",
      "root\n",
      " |-- batiment_id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- type_energie: string (nullable = true)\n",
      " |-- consommation: string (nullable = true)\n",
      " |-- unite: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Afficher le schema infere\n",
    "print(\"Schema infere:\")\n",
    "df_consumption.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c94f0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples de formats de timestamp:\n",
      "+-------------------+\n",
      "|timestamp          |\n",
      "+-------------------+\n",
      "|2023-12-21 13:00:00|\n",
      "|11/29/2024 04:00:00|\n",
      "|09/15/2024 18:00:00|\n",
      "|20/12/2023 07:00   |\n",
      "|29/04/2024 13:00   |\n",
      "|2024-06-15T14:00:00|\n",
      "|22/03/2024 11:00   |\n",
      "|2023-04-07 13:00:00|\n",
      "|2024-03-11T11:00:00|\n",
      "|08/21/2024 17:00:00|\n",
      "|2024-05-27 04:00:00|\n",
      "|08/02/2023 16:00   |\n",
      "|2024-11-23 17:00:00|\n",
      "|2023-07-06T05:00:00|\n",
      "|2024-04-30 02:00:00|\n",
      "|08/12/2023 06:00   |\n",
      "|16/11/2024 21:00   |\n",
      "|12/08/2024 04:00:00|\n",
      "|2024-05-27 10:00:00|\n",
      "|11/03/2023 09:00:00|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "Nombre de valeurs non numeriques: 38,975\n",
      "+------------+\n",
      "|consommation|\n",
      "+------------+\n",
      "|        null|\n",
      "|         N/A|\n",
      "|      erreur|\n",
      "|         ---|\n",
      "+------------+\n",
      "\n",
      "Nombre de valeurs avec virgule: 925,392\n",
      "+------------+\n",
      "|consommation|\n",
      "+------------+\n",
      "|       10,10|\n",
      "|       72,29|\n",
      "|       17,82|\n",
      "|        0,92|\n",
      "|      290,65|\n",
      "+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# PBS DE TYPAGE : \n",
    "\n",
    "# Le timestamp est en string et le format n'est pas toujours le même\n",
    "\n",
    "print(\"Exemples de formats de timestamp:\")\n",
    "df_consumption.select(\"timestamp\").distinct().show(20, truncate=False)\n",
    "\n",
    "# L'unité n'est pas toujours la même (m3,kWh,...)\n",
    "\n",
    "# La consommation est en string : elle peut contenir des virgules et des guillemets, null, N/A, erreur\n",
    "\n",
    "df_non_numeric = df_consumption.filter(\n",
    "    ~F.col(\"consommation\").rlike(\"^-?[0-9]+[.,]?[0-9]*$\")\n",
    ")\n",
    "\n",
    "print(f\"Nombre de valeurs non numeriques: {df_non_numeric.count():,}\")\n",
    "df_non_numeric.select(\"consommation\").distinct().show()\n",
    "\n",
    "# Valeurs avec virgule comme separateur decimal et guillemets\n",
    "df_with_comma = df_consumption.filter(F.col(\"consommation\").contains(\",\"))\n",
    "print(f\"Nombre de valeurs avec virgule: {df_with_comma.count():,}\")\n",
    "df_with_comma.select(\"consommation\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7239dd",
   "metadata": {},
   "source": [
    "## Calculer les statistiques descriptives par type d'energie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99f636cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistiques par type d'energie:\n",
      "+------------+-------+------+-------+--------+--------+------+\n",
      "|type_energie|  count|  mean| stddev|     min|     max|median|\n",
      "+------------+-------+------+-------+--------+--------+------+\n",
      "|         eau|2573156|204.36|2398.57| -657.01|49999.23|  7.52|\n",
      "| electricite|2573364|430.64|2429.51|-4003.35|49999.13|108.56|\n",
      "|         gaz|2573373|560.94|2465.81|-5963.49|49999.49|160.57|\n",
      "+------------+-------+------+-------+--------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convertir consommation en double (en remplacant la virgule par un point)\n",
    "#utilisation de try catch pour correspondance avec vesrion3.4/3.5 de spark\n",
    "df_consumption_numeric = df_consumption.withColumn(\n",
    "    \"conso_clean\",\n",
    "    F.expr(\"try_cast(regexp_replace(cast(consommation as string), ',', '.') as double)\")\n",
    ")\n",
    "\n",
    "# Statistiques par polluant (en ignorant les valeurs nulles)\n",
    "stats_by_energy_type = df_consumption_numeric.filter(F.col(\"conso_clean\").isNotNull()) \\\n",
    "    .groupBy(\"type_energie\") \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"count\"),\n",
    "        F.round(F.mean(\"conso_clean\"), 2).alias(\"mean\"),\n",
    "        F.round(F.stddev(\"conso_clean\"), 2).alias(\"stddev\"),\n",
    "        F.round(F.min(\"conso_clean\"), 2).alias(\"min\"),\n",
    "        F.round(F.max(\"conso_clean\"), 2).alias(\"max\"),\n",
    "        F.round(F.expr(\"percentile(conso_clean, 0.5)\"), 2).alias(\"median\")\n",
    "    ) \\\n",
    "    .orderBy(\"type_energie\")\n",
    "\n",
    "print(\"Statistiques par type d'energie:\")\n",
    "stats_by_energy_type.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab22f656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs negatives:\n",
      "+-----------+-------------------+------------+------------+-----+-----------+\n",
      "|batiment_id|          timestamp|type_energie|consommation|unite|conso_clean|\n",
      "+-----------+-------------------+------------+------------+-----+-----------+\n",
      "|    BAT0075|01/14/2023 08:00:00|         eau|       -6.64|   m3|      -6.64|\n",
      "|    BAT0027|08/31/2023 08:00:00| electricite|     -115.03|  kWh|    -115.03|\n",
      "|    BAT0138|2023-02-13T20:00:00| electricite|     -144.92|  kWh|    -144.92|\n",
      "|    BAT0023|2023-07-17T11:00:00| electricite|     -175.03|  kWh|    -175.03|\n",
      "|    BAT0022|2024-12-04 11:00:00|         eau|       -8.94|   m3|      -8.94|\n",
      "+-----------+-------------------+------------+------------+-----+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Valeurs > 1000 ug/m3:\n",
      "+------------+-----+\n",
      "|type_energie|count|\n",
      "+------------+-----+\n",
      "|         eau|12810|\n",
      "|         gaz|12764|\n",
      "| electricite|12986|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identifier les valeurs aberrantes\n",
    "print(\"Valeurs negatives:\")\n",
    "df_consumption_numeric.filter(F.col(\"conso_clean\") < 0).show(5)\n",
    "\n",
    "print(\"\\nValeurs > 10000 :\")\n",
    "df_consumption_numeric.filter(F.col(\"conso_clean\") > 10000).groupBy(\"type_energie\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf2da37",
   "metadata": {},
   "source": [
    "## Identifier les bâtiments avec le plus de mesures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e4958bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 bâtiments avec le plus de mesures:\n",
      "+-----------+-----+\n",
      "|batiment_id|count|\n",
      "+-----------+-----+\n",
      "|    BAT0086|53275|\n",
      "|    BAT0002|53257|\n",
      "|    BAT0145|53255|\n",
      "|    BAT0117|53254|\n",
      "|    BAT0047|53254|\n",
      "|    BAT0051|53246|\n",
      "|    BAT0093|53242|\n",
      "|    BAT0078|53235|\n",
      "|    BAT0146|53235|\n",
      "|    BAT0046|53233|\n",
      "+-----------+-----+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Nombre d'enregistrements par batiments\n",
    "records_by_building = df_consumption_numeric.groupBy(\"batiment_id\") \\\n",
    "    .count() \\\n",
    "    .orderBy(F.desc(\"count\"))\n",
    "\n",
    "print(\"Top 10 bâtiments avec le plus de mesures:\")\n",
    "records_by_building.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ccc566",
   "metadata": {},
   "source": [
    "## Produire un rapport d'audit de qualite des donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e147ebd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total enregistrements: 7,758,868\n",
      "\n",
      "Problemes identifies:\n",
      "  - Valeurs non numeriques: 38,975 (0.50%)\n",
      "  - Valeurs avec virgule decimale: 925,392 (11.93%)\n",
      "  - Valeurs negatives: 38,910 (0.50%)\n",
      "  - Valeurs aberrantes (>10000): 38,560 (0.50%)\n",
      "  - Doublons: 152,134 (1.96%)\n",
      "  - Formats de dates multiples\n"
     ]
    }
   ],
   "source": [
    "# Resume des problemes\n",
    "\n",
    "total = df_consumption.count()\n",
    "\n",
    "# Valeurs non numeriques\n",
    "non_numeric = df_consumption.filter(\n",
    "    ~F.col(\"consommation\").rlike(\"^-?[0-9]+[.,]?[0-9]*$\")\n",
    ").count()\n",
    "\n",
    "# Consommations avec virgule\n",
    "with_comma = df_consumption.filter(F.col(\"consommation\").contains(\",\")).count()\n",
    "\n",
    "# Valeurs negatives (apres conversion)\n",
    "negative = df_consumption_numeric.filter(F.col(\"conso_clean\") < 0).count()\n",
    "\n",
    "# Valeurs aberrantes > 10000\n",
    "outliers = df_consumption_numeric.filter(F.col(\"conso_clean\") > 10000).count()\n",
    "\n",
    "# Doublons\n",
    "duplicates = total - df_consumption.dropDuplicates([\"batiment_id\", \"timestamp\", \"type_energie\"]).count()\n",
    "\n",
    "\n",
    "print(f\"Total enregistrements: {total:,}\")\n",
    "print()\n",
    "print(f\"Problemes identifies:\")\n",
    "print(f\"  - Valeurs non numeriques: {non_numeric:,} ({non_numeric/total*100:.2f}%)\")\n",
    "print(f\"  - Valeurs avec virgule decimale: {with_comma:,} ({with_comma/total*100:.2f}%)\")\n",
    "print(f\"  - Valeurs negatives: {negative:,} ({negative/total*100:.2f}%)\")\n",
    "print(f\"  - Valeurs aberrantes (>10000): {outliers:,} ({outliers/total*100:.2f}%)\")\n",
    "print(f\"  - Doublons: {duplicates:,} ({duplicates/total*100:.2f}%)\")\n",
    "print(f\"  - Formats de dates multiples\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
