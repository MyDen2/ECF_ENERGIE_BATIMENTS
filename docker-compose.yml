# services:
#   spark-master-test:
#     image: apache/spark:3.5.3
#     container_name: spark-master
#     hostname: spark-master
#     command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
#     environment:
#       - SPARK_MASTER_HOST=spark-master
#       - SPARK_MASTER_PORT=7077
#       - SPARK_MASTER_WEBUI_PORT=8080
#     ports:
#       - "8080:8080"
#       - "7077:7077"
#       - "4040:4040"
#     volumes:
#       - ./data:/data
#       - ./notebooks:/notebooks
#     networks:
#       - spark-network

#   spark-worker-1:
#     image: apache/spark:3.5.3
#     container_name: spark-worker-1
#     hostname: spark-worker-1
#     command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
#     environment:
#       - SPARK_WORKER_CORES=2
#       - SPARK_WORKER_MEMORY=2g
#     depends_on:
#       - spark-master-test
#     volumes:
#       - ./data:/data
#       - ./notebooks:/notebooks
#     networks:
#       - spark-network

#   spark-worker-2:
#     image: apache/spark:3.5.3
#     container_name: spark-worker-2
#     hostname: spark-worker-2
#     command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
#     environment:
#       - SPARK_WORKER_CORES=2
#       - SPARK_WORKER_MEMORY=2g
#     depends_on:
#       - spark-master-test
#     volumes:
#       - ./data:/data
#       - ./notebooks:/notebooks
#     networks:
#       - spark-network

#   spark-worker-3:
#     image: apache/spark:3.5.3
#     container_name: spark-worker-3
#     hostname: spark-worker-3
#     command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
#     environment:
#       - SPARK_WORKER_CORES=2
#       - SPARK_WORKER_MEMORY=2g
#     depends_on:
#       - spark-master-test
#     volumes:
#       - ./data:/data
#       - ./notebooks:/notebooks
#     networks:
#       - spark-network

#   jupyter:
#     image: jupyter/pyspark-notebook:latest
#     container_name: spark-jupyter
#     environment:
#       - JUPYTER_ENABLE_LAB=yes
#       - SPARK_MASTER=spark://spark-master:7077
#     ports:
#       - "8888:8888"
#     volumes:
#       - ./notebooks:/home/jovyan/work
#       - ./data:/home/jovyan/data
#     depends_on:
#       - spark-master-test
#     networks:
#       - spark-network

# networks:
#   spark-network:
#     driver: bridge

#2
# services:
#   spark-master:
#     image: apache/spark:3.5.3
#     container_name: spark-master
#     hostname: spark-master
#     command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
#     environment:
#       - SPARK_MASTER_HOST=spark-master
#       - SPARK_MASTER_PORT=7077
#       - SPARK_MASTER_WEBUI_PORT=8080
#     ports:
#       - "8080:8080"
#       - "7077:7077"
#       - "4040:4040"
#     volumes:
#       - ./data:/data
#       - ./scripts:/scripts
#       - ./output:/output
#       - ./logs:/logs
#       - ./notebooks:/notebooks
#     networks:
#       - spark-network

#   spark-worker-1:
#     image: apache/spark:3.5.3
#     container_name: spark-worker-1
#     hostname: spark-worker-1
#     command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
#     environment:
#       - SPARK_WORKER_CORES=2
#       - SPARK_WORKER_MEMORY=2g
#     depends_on:
#       - spark-master
#     volumes:
#       - ./data:/data
#       - ./scripts:/scripts
#       - ./output:/output
#       - ./logs:/logs
#     networks:
#       - spark-network

#   spark-worker-2:
#     image: apache/spark:3.5.3
#     container_name: spark-worker-2
#     hostname: spark-worker-2
#     command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
#     environment:
#       - SPARK_WORKER_CORES=2
#       - SPARK_WORKER_MEMORY=2g
#     depends_on:
#       - spark-master
#     volumes:
#       - ./data:/data
#       - ./scripts:/scripts
#       - ./output:/output
#       - ./logs:/logs
#     networks:
#       - spark-network

#   spark-worker-3:
#     image: apache/spark:3.5.3
#     container_name: spark-worker-3
#     hostname: spark-worker-3
#     command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
#     environment:
#       - SPARK_WORKER_CORES=2
#       - SPARK_WORKER_MEMORY=2g
#     depends_on:
#       - spark-master
#     volumes:
#       - ./data:/data
#       - ./scripts:/scripts
#       - ./output:/output
#       - ./logs:/logs
#     networks:
#       - spark-network

#   # ✅ service "job" pour exécuter le script CLI
#   spark-job:
#     image: apache/spark:3.5.3
#     container_name: spark-job
#     depends_on:
#       - spark-master
#       - spark-worker-1
#     networks:
#       - spark-network
#     volumes:
#       - ./data:/data:ro
#       - ./scripts:/scripts:ro
#       - ./output:/output
#       - ./logs:/logs
#     # Lance le script en mode cluster via spark-submit
#     command: >
#       /opt/spark/bin/spark-submit
#       --master spark://spark-master:7077
#       --deploy-mode client
#       /scripts/02_nettoyage_spark.py
#       --input /data/consommations_raw.csv
#       --output /output/consommations_clean
#       --log /logs/02_nettoyage_spark.log
#       --outlier-threshold 10000

#   jupyter:
#     image: jupyter/pyspark-notebook:latest
#     container_name: spark-jupyter
#     environment:
#       - JUPYTER_ENABLE_LAB=yes
#       - SPARK_MASTER=spark://spark-master:7077
#     ports:
#       - "8888:8888"
#     volumes:
#       - ./notebooks:/home/jovyan/work
#       - ./data:/home/jovyan/data
#       - ./output:/home/jovyan/output
#     depends_on:
#       - spark-master
#     networks:
#       - spark-network

# networks:
#   spark-network:
#     driver: bridge


services:
  spark-master:
    image: apache/spark:3.5.3
    container_name: spark-master
    hostname: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    ports:
      - "8080:8080"
      - "7077:7077"
      - "4040:4040"
    volumes:
      - ./data_ecf:/data_ecf:ro
      - ./scripts:/scripts:ro
      - ./output:/output
      - ./logs:/logs
      - ./notebooks:/notebooks
    networks:
      - spark-network

  spark-worker-1:
    image: apache/spark:3.5.3
    container_name: spark-worker-1
    hostname: spark-worker-1
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
    depends_on:
      - spark-master
    volumes:
      - ./data_ecf:/data_ecf:ro
      - ./scripts:/scripts:ro
      - ./output:/output
      - ./logs:/logs
    networks:
      - spark-network

  spark-worker-2:
    image: apache/spark:3.5.3
    container_name: spark-worker-2
    hostname: spark-worker-2
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
    depends_on:
      - spark-master
    volumes:
      - ./data_ecf:/data_ecf:ro
      - ./scripts:/scripts:ro
      - ./output:/output
      - ./logs:/logs
    networks:
      - spark-network

  spark-worker-3:
    image: apache/spark:3.5.3
    container_name: spark-worker-3
    hostname: spark-worker-3
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
    depends_on:
      - spark-master
    volumes:
      - ./data_ecf:/data_ecf:ro
      - ./scripts:/scripts:ro
      - ./output:/output
      - ./logs:/logs
    networks:
      - spark-network

  spark-job:
    image: apache/spark:3.5.3
    container_name: spark-job
    depends_on:
      - spark-master
      - spark-worker-1
    networks:
      - spark-network
    volumes:
      - ./data_ecf:/data_ecf:ro
      - ./notebooks:/notebooks:ro
      - ./output:/output
      - ./logs:/logs
    command: >
      /opt/spark/bin/spark-submit
      --master spark://spark-master:7077
      --deploy-mode client
      /notebooks/02_nettoyage_spark.py
      --input /data_ecf/consommations_raw.csv
      --buildings /data_ecf/batiments.csv
      --output /output/consommations_clean
      --log /logs/02_nettoyage_spark.log
      --outlier-threshold 10000
      --master spark://spark-master:7077
      --driver-memory 4g
      --shuffle-partitions 8

  jupyter:
    image: jupyter/pyspark-notebook:latest
    container_name: spark-jupyter
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./data_ecf:/home/jovyan/data_ecf:ro
      - ./output:/home/jovyan/output
      - ./output:/output
    depends_on:
      - spark-master
    networks:
      - spark-network

  pipeline-spark:
    image: apache/spark:3.5.3
    container_name: ecf-pipeline-spark
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2
      - spark-worker-3
    networks:
      - spark-network
    volumes:
      - ./notebooks:/notebooks
      - ./output:/output:rw
      - ./logs:/logs:rw
      - ./data_ecf:/data_ecf:ro
      - ./run_pipeline_spark.sh:/run_pipeline_spark.sh:ro
    entrypoint: ["/bin/bash", "/run_pipeline_spark.sh"]
  
  pipeline-notebooks:
    image: jupyter/pyspark-notebook:python-3.11
    container_name: ecf-pipeline-notebooks
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2
      - spark-worker-3
    networks:
      - spark-network
    volumes:
      - ./notebooks:/notebooks
      - ./output:/output:rw
      - ./logs:/logs:rw
      - ./data_ecf:/data_ecf:ro
      - ./run_pipeline_notebooks.sh:/run_pipeline_notebooks.sh:ro
    command: bash /run_pipeline_notebooks.sh
  
  pipeline:
    build:
      context: .
      dockerfile: Dockerfile.pipeline
    container_name: ecf-pipeline
    volumes:
      - ./scripts:/scripts
      - ./notebooks:/notebooks
      - ./output:/output
      - ./logs:/logs
      - ./data_ecf:/data_ecf
      - ./run_pipeline.sh:/run_pipeline.sh
      - ./run_spark.sh:/run_spark.sh
      - ./run_notebooks.sh:/run_notebooks.sh
    command: bash /run_pipeline.sh
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2
      - spark-worker-3
    networks:
      - spark-network

networks:
  spark-network:
    driver: bridge
